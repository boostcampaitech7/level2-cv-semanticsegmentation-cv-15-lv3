{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import torch\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as osp\n",
    "import albumentations as A\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from tqdm import tqdm\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "class EnsembleDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Soft Voting을 위한 DataSet 클래스입니다. 이 클래스는 이미지를 로드하고 전처리하는 작업과\n",
    "    구성 파일에서 지정된 변환을 적용하는 역할을 수행합니다.\n",
    "\n",
    "    Args:\n",
    "        fnames (set) : 로드할 이미지 파일 이름들의 set\n",
    "        cfg (dict) : 이미지 루트 및 클래스 레이블 등 설정을 포함한 구성 객체\n",
    "        tf_dict (dict) : 이미지에 적용할 Resize 변환들의 dict\n",
    "    \"\"\"    \n",
    "    def __init__(self, fnames, cfg, tf_dict):\n",
    "        self.fnames = np.array(sorted(fnames))\n",
    "        self.image_root = cfg.image_root\n",
    "        self.tf_dict = tf_dict\n",
    "        self.ind2class = {i : v for i, v in enumerate(cfg.CLASSES)}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.fnames)\n",
    "    \n",
    "    def __getitem__(self, item):\n",
    "        \"\"\"\n",
    "        지정된 인덱스에 해당하는 이미지를 로드하여 반환합니다.\n",
    "        Args:\n",
    "            item (int): 로드할 이미지의 index\n",
    "\n",
    "        Returns:\n",
    "            dict : \"image\", \"image_name\"을 키값으로 가지는 dict\n",
    "        \"\"\"        \n",
    "        image_name = self.fnames[item]\n",
    "        image_path = osp.join(self.image_root, image_name)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        assert image is not None, f\"{image_path} 해당 이미지를 찾지 못했습니다.\"\n",
    "        \n",
    "        image = image / 255.0\n",
    "        return {\"image\" : image, \"image_name\" : image_name}\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        \"\"\"\n",
    "        배치 데이터를 처리하는 커스텀 collate 함수입니다.\n",
    "\n",
    "        Args:\n",
    "            batch (list): __getitem__에서 반환된 데이터들의 list\n",
    "\n",
    "        Returns:\n",
    "            dict: 처리된 이미지들을 가지는 dict\n",
    "            list: 이미지 이름으로 구성된 list\n",
    "        \"\"\"        \n",
    "        images = [data['image'] for data in batch]\n",
    "        image_names = [data['image_name'] for data in batch]\n",
    "        inputs = {\"images\" : images}\n",
    "\n",
    "        image_dict = self._apply_transforms(inputs)\n",
    "\n",
    "        image_dict = {k : torch.from_numpy(v.transpose(0, 3, 1, 2)).float()\n",
    "                      for k, v in image_dict.items()}\n",
    "        \n",
    "        for image_size, image_batch in image_dict.items():\n",
    "            assert len(image_batch.shape) == 4, \\\n",
    "                f\"collate_fn 내부에서 image_batch의 차원은 반드시 4차원이어야 합니다.\\n \\\n",
    "                현재 shape : {image_batch.shape}\"\n",
    "            assert image_batch.shape == (len(batch), 3, image_size, image_size), \\\n",
    "                f\"collate_fn 내부에서 image_batch의 shape은 ({len(batch)}, 3, {image_size}, {image_size})이어야 합니다.\\n \\\n",
    "                현재 shape : {image_batch.shape}\"\n",
    "\n",
    "        return image_dict, image_names\n",
    "    \n",
    "    def _apply_transforms(self, inputs):\n",
    "        \"\"\"\n",
    "        입력된 이미지에 변환을 적용합니다.\n",
    "\n",
    "        Args:\n",
    "            inputs (dict): 변환할 이미지를 포함하는 딕셔너리\n",
    "\n",
    "        Returns:\n",
    "            dict : 변환된 이미지들\n",
    "        \"\"\"        \n",
    "        return {\n",
    "            key: np.array(pipeline(**inputs)['images']) for key, pipeline in self.tf_dict.items()\n",
    "        }\n",
    "\n",
    "\n",
    "def encode_mask_to_rle(mask):\n",
    "    # mask map으로 나오는 인퍼런스 결과를 RLE로 인코딩 합니다.\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def load_models(cfg, device):\n",
    "    \"\"\"\n",
    "    구성 파일에 지정된 경로에서 모델을 로드합니다.\n",
    "\n",
    "    Args:\n",
    "        cfg (dict): 모델 경로가 포함된 설정 객체\n",
    "        device (torch.device): 모델을 로드할 장치 (CPU or GPU)\n",
    "\n",
    "    Returns:\n",
    "        dict: 처리 이미지 크기별로 모델을 그룹화한 dict\n",
    "        int: 로드된 모델의 총 개수\n",
    "    \"\"\"    \n",
    "    model_dict = {}\n",
    "    model_count = 0\n",
    "\n",
    "    print(\"\\n======== Model Load ========\")\n",
    "    # inference 해야하는 이미지 크기 별로 모델 순차저장\n",
    "    for key, paths in cfg.model_paths.items():\n",
    "        if len(paths) == 0:\n",
    "            continue\n",
    "        model_dict[key] = []\n",
    "        print(f\"{key} image size 추론 모델 {len(paths)}개 불러오기 진행 시작\")\n",
    "        for path in paths:\n",
    "            print(f\"{osp.basename(path)} 모델을 불러오는 중입니다..\", end=\"\\t\")\n",
    "            model = torch.load(path).to(device)\n",
    "            model.eval()\n",
    "            model_dict[key].append(model)\n",
    "            model_count += 1\n",
    "            print(\"불러오기 성공!\")\n",
    "        print()\n",
    "\n",
    "    print(f\"모델 총 {model_count}개 불러오기 성공!\\n\")\n",
    "    return model_dict, model_count\n",
    "\n",
    "\n",
    "def save_results(cfg, filename_and_class, rles):\n",
    "    \"\"\"\n",
    "    추론 결과를 csv 파일로 저장합니다.\n",
    "\n",
    "    Args:\n",
    "        cfg (dict): 출력 설정을 포함하는 구성 객체\n",
    "        filename_and_class (list): 파일 이름과 클래스 레이블이 포함된 list\n",
    "        rles (list): RLE로 인코딩된 세크멘테이션 마스크들을 가진 list\n",
    "    \"\"\"    \n",
    "    classes, filename = zip(*[x.split(\"_\") for x in filename_and_class])\n",
    "    image_name = [os.path.basename(f) for f in filename]\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"image_name\": image_name,\n",
    "        \"class\": classes,\n",
    "        \"rle\": rles,\n",
    "    })\n",
    "\n",
    "    print(\"\\n======== Save Output ========\")\n",
    "    print(f\"{cfg.save_dir} 폴더 내부에 {cfg.output_name}을 생성합니다..\", end=\"\\t\")\n",
    "    os.makedirs(cfg.save_dir, exist_ok=True)\n",
    "\n",
    "    output_path = osp.join(cfg.save_dir, cfg.output_name)\n",
    "    try:\n",
    "        df.to_csv(output_path, index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"{output_path}를 생성하는데 실패하였습니다.. : {e}\")\n",
    "        raise\n",
    "\n",
    "    print(f\"{osp.join(cfg.save_dir, cfg.output_name)} 생성 완료\")\n",
    "\n",
    "\n",
    "\n",
    "def soft_voting(cfg):\n",
    "    \"\"\"\n",
    "    Soft Voting을 수행합니다. 여러 모델의 예측을 결합하여 최종 예측을 생성\n",
    "\n",
    "    Args:\n",
    "        cfg (dict): 설정을 포함하는 구성 객체\n",
    "    \"\"\"    \n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    fnames = {\n",
    "        osp.relpath(osp.join(root, fname), start=cfg.image_root)\n",
    "        for root, _, files in os.walk(cfg.image_root)\n",
    "        for fname in files\n",
    "        if osp.splitext(fname)[1].lower() == \".png\"\n",
    "    }\n",
    "\n",
    "    tf_dict = {image_size : A.Resize(height=image_size, width=image_size) \n",
    "               for image_size, paths in cfg.model_paths.items() \n",
    "               if len(paths) != 0}\n",
    "    \n",
    "    print(\"\\n======== PipeLine 생성 ========\")\n",
    "    for k, v in tf_dict.items():\n",
    "        print(f\"{k} 사이즈는 {v} pipeline으로 처리됩니다.\")\n",
    "\n",
    "    dataset = EnsembleDataset(fnames, cfg, tf_dict)\n",
    "    \n",
    "    data_loader = DataLoader(dataset=dataset,\n",
    "                             batch_size=cfg.batch_size,\n",
    "                             shuffle=False,\n",
    "                             num_workers=cfg.num_workers,\n",
    "                             drop_last=False,\n",
    "                             collate_fn=dataset.collate_fn)\n",
    "\n",
    "    model_dict, model_count = load_models(cfg, device)\n",
    "    \n",
    "    filename_and_class = []\n",
    "    rles = []\n",
    "\n",
    "    print(\"======== Soft Voting Start ========\")\n",
    "    with torch.no_grad():\n",
    "        with tqdm(total=len(data_loader), desc=\"[Inference...]\", disable=False) as pbar:\n",
    "            for image_dict, image_names in data_loader:\n",
    "                total_output = torch.zeros((cfg.batch_size, len(cfg.CLASSES), 2048, 2048)).to(device)\n",
    "                for name, models in model_dict.items():\n",
    "                    for model in models:\n",
    "                        outputs = model(image_dict[name].to(device))\n",
    "                        outputs = F.interpolate(outputs, size=(2048, 2048), mode=\"bilinear\")\n",
    "                        outputs = torch.sigmoid(outputs)\n",
    "                        total_output += outputs\n",
    "                        \n",
    "                total_output /= model_count\n",
    "                total_output = (total_output > cfg.threshold).detach().cpu().numpy()\n",
    "\n",
    "                for output, image_name in zip(total_output, image_names):\n",
    "                    for c, segm in enumerate(output):\n",
    "                        rle = encode_mask_to_rle(segm)\n",
    "                        rles.append(rle)\n",
    "                        filename_and_class.append(f\"{dataset.ind2class[c]}_{image_name}\")\n",
    "                \n",
    "                pbar.update(1)\n",
    "\n",
    "    save_results(cfg, filename_and_class, rles)\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--config\", type=str, default=\"utils/soft_voting_setting.yaml\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    with open(args.config, 'r') as f:\n",
    "        cfg = OmegaConf.load(f)\n",
    "\n",
    "    if cfg.root_path not in sys.path:\n",
    "        sys.path.append(cfg.root_path)\n",
    "    \n",
    "    soft_voting(cfg)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
